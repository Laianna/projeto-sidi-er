{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import funcoes_modelos as fmod\n",
    "import funcoes_bow as fbow\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "flag_cpu = True\n",
    "if flag_cpu == True:\n",
    "    # force CPU (make CPU visible)\n",
    "    cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "    print(cpus)\n",
    "    tf.config.set_visible_devices([], 'GPU')  # hide the GPU\n",
    "    tf.config.set_visible_devices(cpus[0], 'CPU') # unhide potentially hidden CPU\n",
    "    tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = ['hn_balanceado', 'hn_desbalanceado', 'sn_balanceado', 'sn_desbalanceado']\n",
    "\n",
    "lista_df = []\n",
    "for arquivo in arquivos:\n",
    "\n",
    "    df = pd.read_csv(f\"Dados/Datasets/{arquivo}.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_df[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t\t| Hard\t| Soft\t|\n",
      "Balanceado\t| 8400\t| 8400\t|\n",
      "Desbalanceado\t| 13290\t| 13290\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t\\t| Hard\\t| Soft\\t|\\nBalanceado\\t| {lista_df[0].shape[0]}\\t| {lista_df[2].shape[0]}\\t|\\nDesbalanceado\\t| {lista_df[1].shape[0]}\\t| {lista_df[3].shape[0]}\\t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid(df):\n",
    "    \n",
    "    X = df[[\"titulo_1\", \"titulo_2\"]]\n",
    "    y = df[\"match\"].to_list()\n",
    "    \n",
    "    X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED, stratify = y)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.285, random_state = SEED, stratify = y_train_valid)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_train_test_valid = []\n",
    "for df in lista_df:\n",
    "    lista_train_test_valid.append(train_test_valid(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome, dataset in zip(arquivos, lista_train_test_valid):    \n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos Com Os Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT, roBERTa, XLMR e ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16756/2167009006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelo in modelos:\n",
    "    \n",
    "    lista_df_resultado = []\n",
    "    \n",
    "    for nome, dataset in zip(arquivos, lista_train_test_valid):    \n",
    "        \n",
    "        X_train, y_train, X_test, y_test, X_valid, y_valid = dataset\n",
    "\n",
    "        start_time = time.time()\n",
    "        (nome, historico, y_test, y_pred) = fmod.pipeline_bert(modelo, nome, X_train[:5], y_train[:5], X_valid[:5], y_valid[:5], X_test[:5], y_test[:5])\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        pd.DataFrame.from_dict(historico.history).to_csv(f'Dados/Resultados/{modelo}/{nome}_historico.csv', index = False)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        \n",
    "        df_resultado = salvar_df_resultado(report, modelo, nome, runtime)\n",
    "\n",
    "        lista_df_resultado.append(df_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW Co ocorrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>modelo</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>BoW</td>\n",
       "      <td>hn_balanceado</td>\n",
       "      <td>31.66017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>BoW</td>\n",
       "      <td>hn_balanceado</td>\n",
       "      <td>31.66017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>BoW</td>\n",
       "      <td>hn_balanceado</td>\n",
       "      <td>31.66017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2520.000000</td>\n",
       "      <td>BoW</td>\n",
       "      <td>hn_balanceado</td>\n",
       "      <td>31.66017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>2520.000000</td>\n",
       "      <td>BoW</td>\n",
       "      <td>hn_balanceado</td>\n",
       "      <td>31.66017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support modelo  \\\n",
       "0              0.833333  1.000000  0.909091  2100.000000    BoW   \n",
       "1              0.000000  0.000000  0.000000   420.000000    BoW   \n",
       "accuracy       0.833333  0.833333  0.833333     0.833333    BoW   \n",
       "macro avg      0.416667  0.500000  0.454545  2520.000000    BoW   \n",
       "weighted avg   0.694444  0.833333  0.757576  2520.000000    BoW   \n",
       "\n",
       "                    dataset     tempo  \n",
       "0             hn_balanceado  31.66017  \n",
       "1             hn_balanceado  31.66017  \n",
       "accuracy      hn_balanceado  31.66017  \n",
       "macro avg     hn_balanceado  31.66017  \n",
       "weighted avg  hn_balanceado  31.66017  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_df_resultado[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridade de Cosseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "###Bag of Words###\n",
    "def get_cos(dataframe):\n",
    "\n",
    "    cosine_list = []\n",
    "    \n",
    "    vectors, vectorizer = fbow.vectorize_dataframe(dataframe, binario = False)\n",
    "        \n",
    "    for i in range(0, len(vectors), 2):\n",
    "        cosine_list.append(1 - spatial.distance.cosine(vectors[i], vectors[i+1]))\n",
    "    \n",
    "    return cosine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_cos(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "665796ea3363072d3a6057ac2fdbe3c4fcb0d17a4b92295d9707f78e9c46c0af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
